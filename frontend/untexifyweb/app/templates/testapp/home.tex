% Created 2023-05-21 Sun 12:40
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\author{Robert Grimley}
\date{\today}
\title{Untexify - a bad clone of \href{https://detexify.kirelabs.org/classify.html}{Detexify}}
\hypersetup{
 pdfauthor={Robert Grimley},
 pdftitle={Untexify - a bad clone of \href{https://detexify.kirelabs.org/classify.html}{Detexify}},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 28.1 (Org mode 9.6)}, 
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents

\section{What this is}
\label{sec:org79458b2}
Untexify is handwriting-to- \(\LaTeX\) dictionary. \(\LaTeX\) is the most popular markup language for technical documents in mathematics, and is widely used throughout computer science and industry.

However, its mnemonic conventions for symbols are old and debatably antiquated. Many beginning researchers and students of the sciences find difficulty remembering the \(\LaTeX\) name for a certain symbol. Untexify is an interactive canvas which will return the closest \(\LaTeX\) code for any symbol drawn on it.

This is accomplished using an OCR machine learning model written in Python using TensorFlow, which is then ran in a webapp created with \href{https://www.djangoproject.com/}{Django} hosted online with the help of \href{https://fly.io/}{fly.io}.

The training dataset was not hand-drawn, like in the case of many other MNIST-like models. Rather, it was programmatically generated using an image-transformation pipeline created with the \href{https://albumentations.ai/}{Albumentations} library. This way, I didn't have to find or write myself thousands of hand-drawn \(\LaTeX\).

This entire project was planned and conceived in the lovely \href{https://orgmode.org/}{Org-mode}, as Emacs is my primary development tool. The website was itself written as a series of HTML and Javascript codeblocks which were tangled together using Org-mode's exporting functionality.

This README is also my planning document, and contains annotations and citations for the various steps of the project. This is not only to lower the barrier of entry to someone trying something similar, but also for my future reference.

\section{Road-map}
\label{sec:orge1b53d6}
\subsection{Backend}
\label{sec:orgb3b8d82}
\subsubsection{Create the dataset}
\label{sec:org4e2212a}
\begin{enumerate}
\item Pull a large list of symbols from \href{https://oeis.org/wiki/List\_of\_LaTeX\_mathematical\_symbols}{OEIS}
\label{sec:orga267a0a}

I simply copied a table's symbols and formatted them into a file such that each piece of\(\latex\) was on its own line.
\item Convert them into .png files
\label{sec:org262aea8}

I used \href{https://github.com/mtyrolski/latex2image.git}{latex2image} to convert the list of commands into small, square images of each symbol. The program is a bit finnicky, so for future reference, I placed the file containing my equations called \texttt{equations.txt} the root of the git repository, then ran from the root:
\begin{verbatim}
    cd src/
    . set.sh $absolute_path_to_equations_txt
    cd ..
    cd equations.txt_aux
    python generate_latex.py
\end{verbatim}
I numbered the resulting files using Dired.
\item Sort them into classes based on their\(\latex\) code
\label{sec:org637709f}

I created my images folder, and used this bit of bash magic to sort them into subfolders sharing their same names:
\begin{verbatim}
    for i in $(seq 0 $IMAGE_COUNT); do mkdir $i; mv $i.png $i/; done
\end{verbatim}
Which resulted in:
\begin{center}
\begin{tabular}{r}
0\\\empty
1\\\empty
10\\\empty
11\\\empty
12\\\empty
13\\\empty
14\\\empty
15\\\empty
16\\\empty
17\\\empty
18\\\empty
19\\\empty
2\\\empty
20\\\empty
21\\\empty
22\\\empty
23\\\empty
24\\\empty
25\\\empty
26\\\empty
27\\\empty
28\\\empty
29\\\empty
3\\\empty
30\\\empty
31\\\empty
32\\\empty
33\\\empty
34\\\empty
35\\\empty
36\\\empty
37\\\empty
38\\\empty
39\\\empty
4\\\empty
40\\\empty
41\\\empty
42\\\empty
43\\\empty
44\\\empty
45\\\empty
46\\\empty
47\\\empty
48\\\empty
49\\\empty
5\\\empty
50\\\empty
51\\\empty
52\\\empty
6\\\empty
7\\\empty
8\\\empty
9\\\empty
\end{tabular}
\end{center}

\item Simulate handwriting
\label{sec:org3ca1474}

To do this I need a series of ``transforms'' which will piecewise randomly affect an aspect of a given image. This prevents overfitting, and in the first phase makes the model functional at all. Here are the aspects of the image I chose to transform:

\begin{center}
\begin{tabular}{ll}
\hline
Writing aspect & Transform name\\\empty
\hline
``wiggliness'' or poor handwriting & \texttt{A.ElasticTransform()}\\\empty
Sharpening & \texttt{A.Sharpen()}\\\empty
Uniform color & \texttt{A.Equalize()}\\\empty
Orientation/rotation & \\\empty
Scale & \\\empty
\hline
\end{tabular}
\end{center}
\begin{enumerate}
\item Translation and scale
\label{sec:org590e08b}
Although a textbook cited at the keras docs mentions that convolution layers \emph{should} be translation invariant, a cursory test of my model indicates they are definitely not. So, I need to alter the transformation stack accordingly. The model is also not resistant to the scale of the input, so I need to fix that as well.
\item Stroke
\label{sec:org2bb8bf6}
The model is not resistant to different strokes. Depending on the way I implement the frontend, there may be no reason to train the model to recognize this.
\item Choose a list of symbols
\label{sec:org7df55ae}
Initially, I chose a sample of 50 symbols picked mostly arbitrarily. The initial sample includes multiple sets of symbols which would be similarly drawn (\(\prec\) and \(<\), for example), and also made liberal use of ``\(\not\)'''s (\textlnot{}'s). Because no large public facing database of small\(\latex\) symbols in the model's format exists, and the transform stack is prohibitively computationally expensive, I had to decide what my relatively small data set will contain. I decided on a set of symbols composed mostly of some of the most popular mathematical symbols.

This might be a bit paradoxical, because those symbols which are most popular surely are the most remembered. This may be true, but it is also true that there are probably more beginning researchers and students in need of a reference for basic symbols than there are people who need to look up the more esoteric symbols. Since \href{https://detexify.kirelabs.org/classify.html}{detexify} exists and has a more comprehensive database, I choose for my tool to be more of a quick reference.
\end{enumerate}
\end{enumerate}

\subsubsection{Train the model}
\label{sec:orgc51da67}
\subsection{Frontend}
\label{sec:org6177b26}
\subsubsection{Hosting}
\label{sec:org0c472c7}
To host this project I used \href{https://fly.io/}{fly.io} for its excellent integration with \href{https://www.djangoproject.com/}{Django}, which was used to construct the frontend. Fly.io extremely simple installation instructions for a number of web-app libraries for popular languages, and it was overall very simple to use for someone not experienced in website hosting like myself.
\subsubsection{Website structure}
\label{sec:org20a0569}
The frontend's structure was made entirely using Django, which was excellent for me as someone with lots of python experience, and little HTML or CSS experience.
Most of the interface between the model (which was made using another python library, Tensorflow) and the page was handled in a single \href{frontend/untexifyweb/untexify/views.py}{views.py} file. Python acted as the glue between Django and Tensorflow, which was extremely helpful and satisfying to work with.
Those parts of the website I needed to actually delve into HTML for, were done almost entirely using org-mode's helpful HTML export. I could export large swaths of org-mode documents to a nice-looking CSS ``frame'', while embedding HTML within the plain org text for seamless integration into the final product.

\section{Testing exporting with blocks}
\label{sec:org621c799}
This block is the javascript code for the HTML canvas responsible for accepting user input, in the form of hand-drawn approximations of the symbol they are trying to look up.
Now, we render embed the user-facing HTML elements onto the page.
\end{document}
